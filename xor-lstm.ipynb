{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem statement:\n",
    "https://blog.openai.com/requests-for-research-2/\n",
    "\n",
    "Train an LSTM to solve the XOR problem: that is, given a sequence of bits, determine its parity. The LSTM should consume the sequence, one bit at a time, and then output the correct answer at the sequenceâ€™s end. Test the two approaches below:\n",
    "\n",
    "* Generate a dataset of random 100,000 binary strings of length 50. Train the LSTM; what performance do you get?\n",
    "* Generate a dataset of random 100,000 binary strings, where the length of each string is independently and randomly chosen between 1 and 50. Train the LSTM. Does it succeed? What explains the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 100k strings of length 50, and a function to check the parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n_examples=100000\n",
    "example_length=50\n",
    "data_raw=np.random.randint(2, size=(n_examples, example_length, 1))\n",
    "data_tensor=torch.Tensor(data_raw)\n",
    "def get_parity(arr):\n",
    "    p=np.sum(arr) % 2\n",
    "    return int(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull a random example from the list. Truncate to length `d_max` (so we can test or train with shorter strings), and also allow a `random_truncate` flag which will truncate to a length uniformally distributed from 0 to d_max.\n",
    "\n",
    "Outputs are variables, parity should be integer tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRandomExample(d_max=example_length, random_truncate=True):\n",
    "    l=np.random.randint(n_examples)\n",
    "    d=min(d_max, example_length)\n",
    "    if (random_truncate):\n",
    "        d=np.random.randint(d)\n",
    "    tensor=torch.zeros(d+1, 1, 2)\n",
    "    example_data=data_raw[l,:d+1]\n",
    "    tensor[:,0,0]=1-torch.Tensor(example_data)\n",
    "    tensor[:,0,1]=torch.Tensor(example_data)\n",
    "    return Variable(torch.LongTensor([get_parity(example_data)])), Variable(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM followed by a linear layer to squish or expand to output size, then logsoftmax to produce probabilities.\n",
    "\n",
    "Note the LSTM can take the whole string as input and will apply iteratively. It also returns a value for every stage, which is why we take the last value from its `output` for the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, n_hidden, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, n_hidden, n_layers)\n",
    "        self.lin = nn.Linear(n_hidden, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "    def forward(self, input, hidden):\n",
    "        output, hn = self.rnn(input, hidden)\n",
    "        out = self.softmax(self.lin(output[-1]))\n",
    "        return out, hn\n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(self.n_layers, 1, self.n_hidden))\n",
    "        c0 = Variable(torch.zeros(self.n_layers, 1, self.n_hidden))\n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we're trying to model is very simple, we only need one hidden cell and one layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 1\n",
    "n_layers = 1\n",
    "n_batch = 1\n",
    "input_size = 2\n",
    "output_size=2\n",
    "np.random.seed(1)\n",
    "model=LSTM(input_size, output_size, n_hidden, n_layers)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training! We count a result as correct if the output of the right answer is > 50%. \n",
    "\n",
    "This training starts at a string length of 1 and increments the string length once more than 95% of results are correct. It always uses the length randomization. This leads to *much* faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99[1]: 59/100 loss: 65.654\n",
      "199[1]: 92/100 loss: 50.949\n",
      "299[1]: 100/100 loss: 18.023\n",
      "399[2]: 80/100 loss: 57.065\n",
      "499[2]: 86/100 loss: 46.193\n",
      "599[2]: 88/100 loss: 42.437\n",
      "699[2]: 89/100 loss: 38.163\n",
      "799[2]: 90/100 loss: 33.627\n",
      "899[2]: 86/100 loss: 38.834\n",
      "999[2]: 85/100 loss: 37.220\n",
      "1099[2]: 88/100 loss: 31.482\n",
      "1199[2]: 91/100 loss: 26.364\n",
      "1299[2]: 87/100 loss: 29.151\n",
      "1399[2]: 86/100 loss: 25.314\n",
      "1499[2]: 90/100 loss: 21.643\n",
      "1599[2]: 94/100 loss: 12.065\n",
      "1699[2]: 94/100 loss: 15.891\n",
      "1799[2]: 100/100 loss: 11.709\n",
      "1899[3]: 89/100 loss: 32.375\n",
      "1999[3]: 92/100 loss: 30.304\n",
      "2099[3]: 100/100 loss: 11.724\n",
      "2199[4]: 100/100 loss: 9.433\n",
      "2299[5]: 100/100 loss: 8.575\n",
      "2399[6]: 100/100 loss: 6.932\n",
      "2499[7]: 100/100 loss: 5.786\n",
      "2599[8]: 100/100 loss: 4.712\n",
      "2699[9]: 100/100 loss: 4.650\n",
      "2799[10]: 100/100 loss: 4.334\n",
      "2899[11]: 100/100 loss: 3.718\n",
      "2999[12]: 100/100 loss: 3.614\n",
      "3099[13]: 100/100 loss: 3.424\n",
      "3199[14]: 100/100 loss: 2.362\n",
      "3299[15]: 100/100 loss: 2.812\n",
      "3399[16]: 100/100 loss: 2.533\n",
      "3499[17]: 100/100 loss: 2.204\n",
      "3599[18]: 100/100 loss: 2.328\n",
      "3699[19]: 100/100 loss: 1.988\n",
      "3799[20]: 100/100 loss: 2.037\n",
      "3899[21]: 100/100 loss: 1.594\n",
      "3999[22]: 100/100 loss: 1.883\n",
      "4099[23]: 100/100 loss: 1.604\n",
      "4199[24]: 100/100 loss: 1.522\n",
      "4299[25]: 100/100 loss: 1.645\n",
      "4399[26]: 100/100 loss: 1.473\n",
      "4499[27]: 100/100 loss: 1.392\n",
      "4599[28]: 100/100 loss: 1.420\n",
      "4699[29]: 100/100 loss: 1.339\n",
      "4799[30]: 100/100 loss: 1.319\n",
      "4899[31]: 100/100 loss: 1.163\n",
      "4999[32]: 100/100 loss: 1.371\n",
      "5099[33]: 100/100 loss: 1.316\n",
      "5199[34]: 100/100 loss: 1.323\n",
      "5299[35]: 100/100 loss: 0.965\n",
      "5399[36]: 100/100 loss: 1.107\n",
      "5499[37]: 100/100 loss: 0.877\n",
      "5599[38]: 100/100 loss: 0.896\n",
      "5699[39]: 100/100 loss: 1.006\n",
      "5799[40]: 100/100 loss: 0.908\n",
      "5899[41]: 100/100 loss: 0.953\n",
      "5999[42]: 100/100 loss: 0.874\n",
      "6099[43]: 100/100 loss: 0.832\n",
      "6199[44]: 100/100 loss: 0.803\n",
      "6299[45]: 100/100 loss: 0.824\n",
      "6399[46]: 100/100 loss: 0.896\n",
      "6499[47]: 100/100 loss: 0.824\n",
      "6599[48]: 100/100 loss: 0.671\n",
      "6699[49]: 100/100 loss: 0.738\n",
      "6799[50]: 100/100 loss: 0.848\n",
      "6899[50]: 100/100 loss: 0.784\n",
      "6999[50]: 100/100 loss: 0.699\n",
      "7099[50]: 100/100 loss: 0.938\n",
      "7199[50]: 100/100 loss: 0.714\n",
      "7299[50]: 100/100 loss: 0.813\n",
      "7399[50]: 100/100 loss: 0.618\n",
      "7499[50]: 100/100 loss: 0.681\n",
      "7599[50]: 100/100 loss: 0.740\n",
      "7699[50]: 100/100 loss: 0.711\n",
      "7799[50]: 100/100 loss: 0.575\n",
      "7899[50]: 100/100 loss: 0.698\n",
      "7999[50]: 100/100 loss: 0.591\n",
      "8099[50]: 100/100 loss: 0.656\n",
      "8199[50]: 100/100 loss: 0.526\n",
      "8299[50]: 100/100 loss: 0.579\n",
      "8399[50]: 100/100 loss: 0.435\n",
      "8499[50]: 100/100 loss: 0.547\n",
      "8599[50]: 100/100 loss: 0.598\n",
      "8699[50]: 100/100 loss: 0.519\n",
      "8799[50]: 100/100 loss: 0.545\n",
      "8899[50]: 100/100 loss: 0.552\n",
      "8999[50]: 100/100 loss: 0.566\n",
      "9099[50]: 100/100 loss: 0.507\n",
      "9199[50]: 100/100 loss: 0.522\n",
      "9299[50]: 100/100 loss: 0.517\n",
      "9399[50]: 100/100 loss: 0.462\n",
      "9499[50]: 100/100 loss: 0.522\n",
      "9599[50]: 100/100 loss: 0.479\n",
      "9699[50]: 100/100 loss: 0.436\n",
      "9799[50]: 100/100 loss: 0.434\n",
      "9899[50]: 100/100 loss: 0.501\n",
      "9999[50]: 100/100 loss: 0.439\n"
     ]
    }
   ],
   "source": [
    "print_freq = 100\n",
    "np.random.seed(1)\n",
    "correct = 0\n",
    "count = 0\n",
    "total_loss = 0.0\n",
    "dmax=1\n",
    "for i in range(0,10000):\n",
    "    model.zero_grad()\n",
    "    target, input = getRandomExample(d_max=dmax)\n",
    "    hidden = model.init_hidden()\n",
    "    output, hn = model(input, hidden)\n",
    "    loss = loss_function(output, target)\n",
    "    loss.backward()\n",
    "    total_loss += loss.data[0]\n",
    "    optimizer.step()\n",
    "    if (np.exp(output.data[0,target.data[0]]) > 0.5):\n",
    "        correct += 1\n",
    "    count += 1\n",
    "    if (i % print_freq == print_freq-1): \n",
    "        print('{0}[{1}]: {2}/{3} loss: {4:.3f}'.format(i, dmax, correct, count, total_loss))\n",
    "        if (correct/count > 0.95):\n",
    "            dmax=min(dmax+1,example_length)\n",
    "        correct=0\n",
    "        count=0\n",
    "        total_loss=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
